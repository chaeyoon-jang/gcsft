{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79288257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import sys \n",
    "sys.path.append('..')\n",
    "import pandas as pd \n",
    "from utils.utils import read_jsonl, extract_hash_answer\n",
    "from utils.prompt_hub import get_confidence_prompt\n",
    "\n",
    "def ruler_eval_func(base_url, predict_url):\n",
    "    base = read_jsonl(base_url)\n",
    "    check = read_jsonl(predict_url)\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    for b, predict in zip(base, check):\n",
    "        targets.append([p.lower() for p in predict['reference']])\n",
    "        if b['task_label'] == 'cwe' or b['task_label'] == 'fwe' or b['task_label'] == 'vt':\n",
    "            predicts.append([re.sub(r'[^a-zA-Z]', '', w).lower() for w in predict['completion'].split(\" \")])\n",
    "        elif b['task_label'] == 'niah_multikey_1' or b['task_label'] == 'niah_multikey_2' or b['task_label'] == 'niah_single_1' or b['task_label'] == 'niah_single_2':\n",
    "            predicts.append([re.sub(r'[^0-9]', '', predict['completion']).lower()]) \n",
    "        elif b['task_label'] == 'niah_multikey_3' or b['task_label'] == 'niah_single_3':\n",
    "            predicts.append([re.sub(r'[^a-zA-Z0-9-]', '', predict['completion']).lower()])\n",
    "        elif b['task_label'] == 'niah_multiquery' or b['task_label'] == 'niah_multivalue':\n",
    "            predicts.append([re.sub(r'[^0-9]', '', w).lower() for w in predict['completion'].split(\" \")])\n",
    "        else:\n",
    "            predicts.append([predict['completion'].lower()])\n",
    "    tf = []\n",
    "    #new_p = []\n",
    "    for b, p, t in zip(base, predicts, targets):\n",
    "        p = [x for x in p if x != '']\n",
    "        #new_p.append(p)\n",
    "        if 'qa' in b['task_label']:\n",
    "            if set(p).issubset(set(t)):\n",
    "                tf.append(1)\n",
    "            else:\n",
    "                tf.append(0)\n",
    "        else:\n",
    "            try:\n",
    "                if set(p) == set(t):\n",
    "                    tf.append(1)\n",
    "                else:\n",
    "                    tf.append(0) \n",
    "            except:\n",
    "                print(p)\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea2403",
   "metadata": {},
   "source": [
    "## Make Llama-3.2-3B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5f8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ruler training datasets\n",
    "ruler_4k_base = read_jsonl('../logs/trash/llama/ruler_4k_train_seed_samples/outputs_base_argmax.jsonl')\n",
    "\n",
    "ruler_4k_samples_tf = []\n",
    "for i in range(10):\n",
    "    temp_tf = ruler_eval_func('../data/processed/ruler_4k_train.jsonl', f'../logs/trash/llama/ruler_4k_train_seed_samples/outputs_seed_{i}.jsonl')\n",
    "    ruler_4k_samples_tf.append(temp_tf)\n",
    "    \n",
    "conf_labels = []\n",
    "for i in range(len(ruler_4k_base)):\n",
    "    count = 0\n",
    "    for j in range(10):\n",
    "        count += ruler_4k_samples_tf[j][i]\n",
    "    conf_labels.append(str(int(count*10)))\n",
    "    \n",
    "ruler_train_data = pd.DataFrame({\n",
    "    'input_prompt': [x['input'] for x in ruler_4k_base],\n",
    "    'predicted_answer': [x['completion'] for x in ruler_4k_base],\n",
    "    'target_answer': [x['reference'] for x in ruler_4k_base],\n",
    "    'conf_input_single': [x['input'] + x['completion'] + \"</answer>\\n\\n\" +get_confidence_prompt('default')[:-12] for x in ruler_4k_base],\n",
    "    'conf_input_multi': [x['input'] + x['completion'] + \"</answer>\\n\\n\" +get_confidence_prompt('multi')[:-22] + \"<reasoning_confidence>N/A</reasoning_confidence>\\n<evidence_confidence>\" for x in ruler_4k_base],\n",
    "    'conf_label_single': [\"<confidence>\" + c + \"</confidence>\" for c in conf_labels],\n",
    "    'conf_label_multi': [ c + \"</evidence_confidence>\" for c in conf_labels],\n",
    "    'task_type': ['ruler' for _ in range(len(ruler_4k_base))]})\n",
    "\n",
    "## ruelr validation datasets \n",
    "ruler_4k_base = read_jsonl('../logs/trash/llama/ruler_4k_valid_seed_samples/outputs_base_argmax.jsonl')\n",
    "\n",
    "ruler_4k_samples_tf = []\n",
    "for i in range(10):\n",
    "    temp_tf = ruler_eval_func('../data/processed/ruler_4k_valid.jsonl', f'../logs/trash/llama/ruler_4k_valid_seed_samples/outputs_seed_{i}.jsonl')\n",
    "    ruler_4k_samples_tf.append(temp_tf)\n",
    "    \n",
    "conf_labels = []\n",
    "for i in range(len(ruler_4k_base)):\n",
    "    count = 0\n",
    "    for j in range(10):\n",
    "        count += ruler_4k_samples_tf[j][i]\n",
    "    conf_labels.append(str(int(count*10)))\n",
    "    \n",
    "ruler_valid_data = pd.DataFrame({\n",
    "    'input_prompt': [x['input'] for x in ruler_4k_base],\n",
    "    'predicted_answer': [x['completion'] for x in ruler_4k_base],\n",
    "    'target_answer': [x['reference'] for x in ruler_4k_base],\n",
    "    'conf_input_single': [x['input'] + x['completion'] + \"</answer>\\n\\n\" + get_confidence_prompt('default')[:-12] for x in ruler_4k_base],\n",
    "    'conf_input_multi': [x['input'] + x['completion'] + \"</answer>\\n\\n\" + get_confidence_prompt('multi')[:-22] + \"<reasoning_confidence>N/A</reasoning_confidence>\\n<evidence_confidence>\" for x in ruler_4k_base],\n",
    "    'conf_label_single': [\"<confidence>\" + c + \"</confidence>\" for c in conf_labels],\n",
    "    'conf_label_multi': [c + \"</evidence_confidence>\" for c in conf_labels],\n",
    "    'task_type': ['ruler' for _ in range(len(ruler_4k_base))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4655daff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 15 Jan 2026\n",
      "\n",
      "You are an expert assistant that provides clear and helpful answers.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "You are an answering assistant.\n",
      "Given a question, provide the final answer.\n",
      "Respond with the answer enclosed in <answer> and </answer> tags.\n",
      "The <answer> tag must contain only the final answer, with no additional explanation.\n",
      "\n",
      "Below is a numbered list of words. In these words, some appear more often than others. Memorize the ones that appear most often.\n",
      "1. gratitude 2. wheel 3. attorney 4. company 5. tortilla 6. mortise 7. develop 8. boyhood 9. mortise 10. chin 11. boyhood 12. denominator 13. wheel 14. denominator 15. hygienic 16. district 17. armchair 18. freak 19. wheel 20. hygienic 21. attorney 22. overview 23. lovely 24. gratitude 25. gratitude 26. freak 27. clearance 28. runway 29. hygienic 30. attorney 31. bench 32. blush 33. tortilla 34. freak 35. denominator 36. mortise 37. tortilla 38. blush 39. boyhood 40. blush\n",
      "Question: What are the 10 most common words in the above list? Answer: The top 10 words that appear most often in the list are: 1. attorney 2. boyhood 3. hygienic 4. wheel 5. mortise 6. tortilla 7. freak 8. blush 9. denominator 10. gratitude\n",
      "Below is a numbered list of words. In these words, some appear more often than others. Memorize the ones that appear most often.\n",
      "1. frustration 2. effector 3. specify 4. due 5. channel 6. outstanding 7. birdbath 8. sandal 9. accessory 10. jailhouse 11. dynamics 12. restoration 13. grasshopper 14. beastie 15. elimination 16. exclusive 17. thousand 18. past 19. kayak 20. painful 21. win 22. bicycle 23. skinny 24. gang 25. mean 26. anticipate 27. idiotic 28. reversal 29. cobweb 30. browsing 31. vase 32. yoke 33. software 34. ideal 35. table 36. standardization 37. stopwatch 38. doctorate 39. genocide 40. dash 41. ornament 42. chinchilla 43. outrun 44. goddess 45. end 46. bricklaying 47. baritone 48. glutamate 49. chill 50. shape 51. eagle 52. erosion 53. cry 54. sneakers 55. emu 56. hoe 57. convertible 58. cyclone 59. headrest 60. intellect 61. hubris 62. rhubarb 63. larch 64. oil 65. stag 66. forecast 67. forest 68. cutlet 69. angiosperm 70. demonstrate 71. alike 72. characteristic 73. cursor 74. search 75. kale 76. lift 77. baby 78. pattypan 79. bond 80. bond 81. mob 82. mill 83. injure 84. heartbreaking 85. knee 86. panty 87. rooster 88. fanny-pack 89. street 90. chive 91. peel 92. wonder 93. bond 94. tempt 95. immigrant 96. divide 97. idiotic 98. marriage 99. vellum 100. coordination 101. disguise 102. participation 103. fishnet 104. reveal 105. subsection 106. cold 107. soccer 108. peaceful 109. railroad 110. suspend 111. monitor 112. server 113. job 114. meantime 115. rear 116. matrix 117. presume 118. standing 119. prison 120. elevator 121. burlesque 122. move 123. mansion 124. enacted 125. radar 126. insurgence 127. advertising 128. stove 129. tunic 130. hashtag 131. hurried 132. transport 133. doorpost 134. onset 135. silky 136. come 137. murky 138. menorah 139. hug 140. remove 141. listening 142. secrecy 143. relate 144. warren 145. hamster 146. warden 147. mid-course 148. node 149. shape 150. tonic 151. elimination 152. tactics 153. administrator 154. noodle 155. plug 156. barbeque 157. aberrant 158. ukulele 159. whiskey 160. sensitive 161. repulsive 162. ring 163. hurry 164. fedelini 165. wealthy 166. grassland 167. alluvium 168. thoughtless 169. sunbeam 170. sin 171. strategy 172. slap 173. sprout 174. beheading 175. wasabi 176. reveal 177. plaster 178. correct 179. semicircle 180. swim 181. exultant 182. chopstick 183. loaf 184. prior 185. decision-making 186. moustache 187. flick 188. recondite 189. bongo 190. penitent 191. pickle 192. daybed 193. mining 194. cowboy 195. infrastructure 196. bibliography 197. ammunition 198. menorah 199. shape 200. mattress 201. maid 202. bawdy 203. newsstand 204. nephew 205. thought 206. cultured 207. homogenate 208. brother-in-law 209. climate 210. install 211. bomb 212. breadfruit 213. sparkling 214. messy 215. elimination 216. carving 217. rise 218. horn 219. promote 220. runway 221. adjoining 222. tank-top 223. overshoot 224. undergo 225. horseradish 226. reprocessing 227. petite 228. crowded 229. reveal 230. bench 231. spread 232. velocity 233. brand 234. woodshed 235. buddy 236. succinct 237. idiotic 238. detection 239. ranger 240. recognition 241. sadness 242. spectacular 243. tam-o'-shanter 244. fortune 245. nonconformist 246. idiotic 247. coleslaw 248. wording 249. pliers 250. schema 251. spark 252. space 253. haze 254. inexpensive 255. development 256. keeper 257. eclipse 258. overflow 259. appliance 260. instant 261. cling 262. pod 263. adamant 264. rough 265. vulture 266. crystal 267. foundation 268. credibility 269. church 270. beneficiary 271. culture 272. hold 273. ratio 274. ramie 275. recorder 276. mosquito 277. live 278. bite 279. breakfast 280. gigantism 281. thesis 282. tintype 283. ephyra 284. book 285. hyacinth 286. arrange 287. puppet 288. boysenberry 289. melted 290. detector 291. fang 292. simvastatin 293. nauseating 294. division 295. stench 296. bowler 297. mislead 298. crunch 299. sympathy 300. stitch 301. pita 302. instructor 303. remains 304. cheetah 305. doll 306. sip 307. glutamate 308. neurobiologist 309. great 310. calendar 311. seagull 312. prosperity 313. mozzarella 314. tow-truck 315. degree 316. orator 317. clone 318. activate 319. application 320. fountain 321. tick 322. big 323. screenwriting 324. madam 325. fall 326. pantyhose 327. elver 328. lining 329. zoologist 330. reliability 331. situation 332. abide 333. thirst 334. inhibitor 335. recess 336. wasteful 337. restoration 338. ivory 339. publisher 340. neglect 341. founder 342. supreme 343. agency 344. jury 345. utilize 346. weather 347. restoration 348. wallaby 349. cashier 350. orchid 351. toilet 352. misspell 353. pig 354. holiday 355. verse 356. developer 357. fawn 358. longboat 359. difficult 360. skean 361. corporal 362. delegate 363. bond 364. widow 365. lizard 366. pound 367. bond 368. wasp 369. goldfish 370. interrupt 371. ketch 372. timetable 373. paragraph 374. aspic 375. graphic 376. leveret 377. height 378. lonely 379. heterosexual 380. constraint 381. restoration 382. guideline 383. accidental 384. dance 385. disguise 386. shape 387. training 388. wave 389. dressing 390. cabbage 391. architect 392. leek 393. kielbasa 394. bather 395. allocation 396. helpful 397. participant 398. elated 399. cheerful 400. campus 401. verification 402. riser 403. glutamate 404. attach 405. floozie 406. rush 407. idiotic 408. trial 409. spicy 410. juicy 411. wastebasket 412. null 413. bar 414. nifty 415. inventory 416. portion 417. bark 418. muscatel 419. gastronomy 420. acquisition 421. ectodermal 422. stress 423. gigantic 424. cria 425. camper 426. validate 427. employer 428. championship 429. prosecution 430. bankruptcy 431. influence 432. orient 433. seafood 434. sport 435. ski 436. replication 437. glutamate 438. disguise 439. breakable 440. conduct 441. curved 442. wary 443. guard 444. absorbing 445. definition 446. compulsion 447. adviser 448. verdant 449. beautiful 450. durian 451. struggle 452. strong 453. quince 454. parsley 455. draconian 456. strawman 457. rescue 458. successful 459. curly 460. moose 461. otter 462. reveal 463. success 464. advance 465. celebration 466. airfare 467. dial 468. steak 469. denominator 470. cake 471. amazement 472. dazzling 473. glutamate 474. amuse 475. menorah 476. blow 477. sunbonnet 478. constraint 479. candelabra 480. bin 481. lumber 482. samovar 483. batter 484. grab-bag 485. masonry 486. temperature 487. device 488. shrine 489. guess 490. hill 491. booking 492. constraint 493. cummerbund 494. formicarium 495. redirect 496. elimination 497. accompanist 498. famous 499. fuzzy 500. stepmother 501. oatmeal 502. pigsty 503. flour 504. tearful 505. suggestion 506. announcement 507. freezing 508. workplace 509. practice 510. scale 511. apprehension 512. ash 513. bird 514. mutation 515. restoration 516. behold 517. lewd 518. interchange 519. blackberry 520. authorisation 521. pudding 522. tumbler 523. gain 524. pear 525. inability 526. accident 527. menorah 528. constraint 529. indication 530. chino 531. motorcycle 532. heater 533. scrap 534. garment 535. breakdown 536. ginseng 537. hydrant 538. tabernacle 539. herbs 540. substance 541. sunflower 542. tortellini 543. millimeter 544. labour 545. nostalgic 546. sleuth 547. menorah 548. virtue 549. mouser 550. profit 551. carpeting 552. snobbish 553. modern 554. ruthless 555. hackwork 556. cheese 557. trapezoid 558. illness 559. kit 560. pin 561. colony 562. prickly 563. rug 564. disprove 565. abusive 566. enjoyment 567. disclosure 568. limitation 569. kebab 570. anesthesiologist 571. sail 572. weed 573. peripheral 574. disguise 575. orchard 576. bright 577. numerous 578. constraint 579. understood 580. chives 581. genre 582. room 583. export 584. bayou 585. assistance 586. sovereignty 587. homosexual 588. salesman 589. kiss 590. noise 591. supernatural 592. inhabitant 593. leave 594. pop 595. crew 596. unarmed 597. saxophone 598. candy 599. initial 600. boyhood 601. leeway 602. low 603. feather 604. callous 605. warming 606. overcoat 607. frenzy 608. elimination 609. gelding 610. fanlight 611. burial 612. marmalade 613. elimination 614. vintage 615. tunnel 616. harmonise 617. reveal 618. rubric 619. sword 620. cathedral 621. behaviour 622. lot 623. north 624. advocacy 625. tutu 626. special 627. enlist 628. contest 629. psychiatrist 630. tomb 631. examiner 632. idiotic 633. youngster 634. back 635. washbasin 636. co-producer 637. incident 638. pistol 639. grocery 640. rite 641. emphasis 642. constraint 643. burning 644. caboose 645. subtitle 646. monitoring 647. fries 648. caravan 649. circuit 650. livestock 651. gelatin 652. hippopotamus 653. last 654. crazy 655. obstacle 656. impudence 657. bond 658. minnow 659. replica 660. ex-husband 661. alloy 662. fat 663. farrow 664. reform 665. tight 666. deliberation 667. sleepiness 668. composite 669. texture 670. competition 671. fob 672. gearshift 673. embarrassment 674. burden 675. stale 676. creep 677. electronics 678. smoke 679. designation 680. late 681. abdomen 682. analyst 683. flavor 684. essence 685. nitrogen 686. invitation 687. incarnation 688. councilor 689. wrist 690. disguise 691. wear 692. pinot 693. cobbler 694. evaluation 695. manacle 696. carrier 697. info 698. confirmation 699. codling 700. statuesque 701. smelting 702. sociology 703. accountability 704. hurt 705. gap 706. oyster 707. telescreen 708. genius 709. pledge 710. yolk 711. rotation 712. span 713. marked 714. reward 715. inevitable 716. coin 717. rose 718. worried 719. occupation 720. republican 721. final 722. drab 723. lute 724. shape 725. refreshments 726. remember 727. taboo 728. snap 729. clutch 730. mass 731. tinderbox 732. maggot 733. second 734. film 735. disaster 736. incentive 737. sneaky 738. possibility 739. glutamate 740. wing 741. slipper 742. withdrawal 743. note 744. seeker 745. driving 746. doe 747. humorous 748. calculator 749. popsicle 750. strawberry 751. prescription 752. bank 753. kite 754. geyser 755. theme 756. shape 757. basement 758. oat 759. harald 760. dollar 761. necktie 762. role 763. zealous 764. heaven 765. strobe 766. hammer 767. platform 768. disguise 769. pride 770. monocle 771. claim 772. formamide 773. polyp 774. reveal 775. restoration 776. cover 777. ridge 778. minute 779. whey 780. reception 781. stew 782. bottling 783. ikebana 784. shelter 785. readiness 786. spooky 787. frantic 788. souvenir 789. menorah 790. depression 791. pioneer\n",
      "Question: What are the 10 most common words in the above list? Answer: The top 10 words that appear most often in the list are:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<answer>1. attorney 2. boyhood 3. hygienic 4. wheel 5. freak 6. blush 7. denominator 8. gratitude 9. tortilla 10. freak</answer>\n",
      "\n",
      "You are a confidence estimator.\n",
      "Given a question and a model answer, estimate confidence along two independent aspects.\n",
      "1. Reasoning Confidence:\n",
      "How confident are you that the reasoning process leading to the answer is logically sound and free of internal errors?\n",
      "2. Evidence Confidence:\n",
      "How confident are you that the answer is directly supported by the given context or evidence, if any?\n",
      "Respond with two integers from 0 to 100, each enclosed in the corresponding XML tags.\n",
      "Do not include any explanation or additional text.\n",
      "<reasoning_confidence>N/A</reasoning_confidence>\n",
      "<evidence_confidence>0</evidence_confidence>\n",
      "---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 15 Jan 2026\n",
      "\n",
      "You are an expert assistant that provides clear and helpful answers.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "You are an answering assistant.\n",
      "Given a question, provide the final answer.\n",
      "Respond with the answer enclosed in <answer> and </answer> tags.\n",
      "The <answer> tag must contain only the final answer, with no additional explanation.\n",
      "\n",
      "Below is a numbered list of words. In these words, some appear more often than others. Memorize the ones that appear most often.\n",
      "1. spiffy 2. wit 3. atheist 4. pumpkinseed 5. satisfaction 6. livestock 7. multiply 8. boatyard 9. livestock 10. sinuosity 11. boatyard 12. semester 13. wit 14. semester 15. troubled 16. pint 17. health-care 18. wreck 19. wit 20. troubled 21. atheist 22. introduce 23. hacienda 24. spiffy 25. spiffy 26. wreck 27. entree 28. solidity 29. troubled 30. atheist 31. sentence 32. transportation 33. satisfaction 34. wreck 35. semester 36. livestock 37. satisfaction 38. transportation 39. boatyard 40. transportation\n",
      "Question: What are the 10 most common words in the above list? Answer: The top 10 words that appear most often in the list are: 1. atheist 2. boatyard 3. troubled 4. wit 5. livestock 6. satisfaction 7. wreck 8. transportation 9. semester 10. spiffy\n",
      "Below is a numbered list of words. In these words, some appear more often than others. Memorize the ones that appear most often.\n",
      "1. limit 2. enthusiasm 3. tenor 4. flame 5. nature 6. trove 7. oak 8. symptomatic 9. instrumentation 10. evidence 11. advertising 12. cuckoo 13. stockings 14. cribbage 15. licensing 16. intentionality 17. yoga 18. tote 19. lawsuit 20. disco 21. outback 22. sour 23. nutty 24. exhibit 25. backyard 26. anagram 27. nest 28. auto 29. daffy 30. fridge 31. peony 32. like 33. effacement 34. cornet 35. strip 36. pavilion 37. understanding 38. footwear 39. grow 40. comfortable 41. breezy 42. pitcher 43. madam 44. incident 45. priority 46. standoff 47. salesman 48. burrow 49. full 50. bush 51. tailbud 52. wire 53. perfume 54. linseed 55. valley 56. robust 57. fawn 58. plunger 59. zipper 60. dollar 61. ottoman 62. headrest 63. alluvium 64. industrious 65. cathedral 66. exclusive 67. doubtful 68. fish 69. girlfriend 70. cooperation 71. regime 72. blister 73. mochi 74. relate 75. hypothesis 76. consulting 77. feature 78. component 79. summarize 80. summarize 81. liquid 82. sun 83. rowing 84. subsequent 85. salami 86. tone 87. murky 88. font 89. flour 90. compromise 91. snuck 92. use 93. summarize 94. celery 95. centimeter 96. board 97. nest 98. arch 99. attendance 100. parent 101. listen 102. rage 103. rhythm 104. falling-out 105. advance 106. speculation 107. patina 108. tenuous 109. toenail 110. rutabaga 111. internet 112. quality 113. print 114. spin 115. authorisation 116. loaf 117. large 118. narrow 119. denim 120. hatbox 121. holiday 122. allocation 123. lesbian 124. grid 125. trot 126. portrait 127. auction 128. paw 129. lamentable 130. ancestor 131. fratricide 132. traveler 133. host 134. impartial 135. segment 136. diam 137. yeast 138. essay 139. pastry 140. outfielder 141. kiss 142. carport 143. greedy 144. immense 145. weep 146. depression 147. scrap 148. many 149. bush 150. pug 151. licensing 152. software 153. feather 154. kindhearted 155. embassy 156. crow 157. body 158. pop 159. author 160. sorrow 161. sill 162. promenade 163. sparrow 164. clinic 165. harald 166. dandelion 167. ram 168. sari 169. lacking 170. wharf 171. guideline 172. attack 173. thumb 174. chrysalis 175. inhibition 176. falling-out 177. shoulder 178. peer-to-peer 179. chow 180. sleepy 181. backpack 182. resonant 183. association 184. reprocessing 185. git 186. steady 187. numberless 188. detect 189. literate 190. guilty 191. riverbed 192. threat 193. codepage 194. waitress 195. succeed 196. carol 197. hushed 198. essay 199. bush 200. bless 201. infant 202. cilantro 203. wifi 204. manipulate 205. analogy 206. pretzel 207. pencil 208. trigonometry 209. composite 210. select 211. appendix 212. architect 213. unsuitable 214. aid 215. licensing 216. crumb 217. mesenchyme 218. sympathy 219. correct 220. exterior 221. brassiere 222. tankful 223. toot 224. uptight 225. pizza 226. harp 227. anarchist 228. statuesque 229. falling-out 230. tractor 231. bath 232. fitness 233. crotch 234. exasperation 235. data 236. ginseng 237. nest 238. plucky 239. evil 240. flare 241. possibility 242. background 243. client 244. vertigo 245. archaeologist 246. nest 247. dirty 248. main 249. supply 250. sail 251. birdcage 252. wring 253. disillusioned 254. apron 255. custom 256. commodity 257. semester 258. nasty 259. donation 260. square 261. pink 262. numerous 263. morning 264. maize 265. style 266. discover 267. snarl 268. quickest 269. canal 270. grey 271. kingdom 272. squeeze 273. peer 274. cafe 275. irony 276. progress 277. pension 278. uncovered 279. flawless 280. gingerbread 281. instinctive 282. gazelle 283. ceaseless 284. underwear 285. ladle 286. gaudy 287. phenomenon 288. gratitude 289. cross-stitch 290. penalty 291. invent 292. mechanic 293. off-ramp 294. variety 295. disruption 296. assorted 297. glorious 298. trumpet 299. minnow 300. tent 301. marsh 302. marionberry 303. approach 304. cooking 305. bather 306. extract 307. burrow 308. area 309. abdomen 310. zoot-suit 311. cupcake 312. remind 313. south 314. outcome 315. tolerance 316. thrill 317. trashy 318. fair 319. slash 320. handgun 321. nursery 322. ramie 323. incompetence 324. atmosphere 325. restructuring 326. efficiency 327. declaration 328. horror 329. clove 330. differential 331. dryer 332. sneaky 333. candy 334. hallowed 335. alpenglow 336. amazement 337. cuckoo 338. cephalopod 339. hotel 340. tamale 341. makeshift 342. provide 343. shame 344. doctor 345. present 346. lewd 347. cuckoo 348. kick 349. outside 350. archives 351. crane 352. heartbeat 353. revival 354. cappelletti 355. monk 356. hawk 357. credit 358. sad 359. credible 360. opossum 361. collaboration 362. vitality 363. summarize 364. play 365. calculator 366. lend 367. summarize 368. tank 369. accidental 370. stopwatch 371. formula 372. cirrus 373. lashes 374. chance 375. configuration 376. autoimmunity 377. shelter 378. indigence 379. angiosperm 380. hectare 381. cuckoo 382. tow-truck 383. attract 384. become 385. listen 386. bush 387. manage 388. cheer 389. fraud 390. accuracy 391. circumstance 392. steamroller 393. sage 394. add 395. patty 396. slime 397. undertaker 398. antiquity 399. display 400. hover 401. trance 402. shoes 403. burrow 404. recess 405. shear 406. believer 407. nest 408. instrument 409. sling 410. sore 411. routine 412. obey 413. determination 414. doll 415. sunrise 416. vegetable 417. longing 418. baby 419. trace 420. nonbeliever 421. lieutenant 422. intercourse 423. amusement 424. confusion 425. fritter 426. odometer 427. upward 428. unblinking 429. ray 430. defeat 431. scarification 432. espalier 433. ocean 434. jellyfish 435. polarization 436. classy 437. burrow 438. listen 439. mutation 440. crewmen 441. lively 442. excited 443. hip 444. inhibitor 445. create 446. pleat 447. genius 448. trousers 449. patient 450. sense 451. hole 452. guarantee 453. addition 454. octopus 455. plea 456. chivalry 457. judo 458. overweight 459. pour 460. violin 461. angry 462. falling-out 463. jump 464. influx 465. ischemia 466. reflect 467. boss 468. whisper 469. imagination 470. dwelling 471. buddy 472. pillbox 473. burrow 474. saw 475. essay 476. schooner 477. civilisation 478. hectare 479. civilian 480. wildebeest 481. worm 482. styling 483. significance 484. know 485. macro 486. romance 487. mature 488. sleeping 489. turnover 490. patriot 491. strategy 492. hectare 493. sink 494. lesson 495. banquette 496. licensing 497. cloistered 498. fax 499. installation 500. passion 501. vulgar 502. statin 503. prisoner 504. skiing 505. billboard 506. podcast 507. reserve 508. phenotype 509. plot 510. mammoth 511. trust 512. spiral 513. purring 514. rip 515. cuckoo 516. bustle 517. needless 518. leopard 519. mango 520. relief 521. minibus 522. adoption 523. explanation 524. instruct 525. pick 526. ethnicity 527. essay 528. hectare 529. wonderful 530. wedge 531. reinscription 532. prosecutor 533. vogue 534. luck 535. geometry 536. hyphenation 537. linguist 538. procurement 539. dream 540. backburn 541. identify 542. snow 543. jodhpurs 544. crazy 545. pelican 546. abashed 547. essay 548. ordinary 549. walrus 550. candidacy 551. estuary 552. withstand 553. pimple 554. song 555. cent 556. milk 557. major 558. bomb 559. beverage 560. questioner 561. nappy 562. intensify 563. fries 564. monasticism 565. caribou 566. caravan 567. fountain 568. pasture 569. diploma 570. naturalisation 571. ninja 572. save 573. craven 574. listen 575. blocker 576. spoon 577. charlatan 578. hectare 579. country 580. contest 581. tasteful 582. angle 583. outrun 584. scent 585. moth 586. cobbler 587. cover 588. continent 589. tulip 590. tea 591. grain 592. struggle 593. chairman 594. character 595. complexity 596. duck 597. flume 598. diligent 599. trader 600. analogue 601. plover 602. pulse 603. programming 604. priest 605. video 606. napkin 607. brave 608. licensing 609. bait 610. fruit 611. include 612. sincere 613. licensing 614. distinction 615. rabid 616. dissemination 617. falling-out 618. handful 619. harbour 620. apologize 621. endothelium 622. cough 623. leg 624. safeguard 625. bed 626. wide 627. meteorology 628. race 629. translation 630. scorch 631. village 632. nest 633. faith 634. verb 635. ecliptic 636. abhorrent 637. sensitive 638. confused 639. walnut 640. bombing 641. doctrine 642. hectare 643. termite 644. political 645. antecedent 646. chit-chat 647. youngster 648. nonchalant 649. acid 650. willow 651. button 652. bank 653. disappear 654. sport 655. corduroy 656. scarecrow 657. summarize 658. crate 659. dramaturge 660. hardening 661. involvement 662. reflection 663. trooper 664. derivation 665. wiring 666. philosophy 667. responsibility 668. fast 669. department 670. organization 671. guitarist 672. venomous 673. contain 674. judicious 675. uniformity 676. drawing 677. lens 678. treaty 679. cytoplasm 680. fascia 681. priesthood 682. act 683. socialism 684. patriarch 685. flight 686. skull 687. statement 688. rotation 689. stroke 690. listen 691. shot 692. find 693. glacier 694. import 695. bail 696. tonality 697. catalog 698. approve 699. itch 700. church 701. acquisition 702. processor 703. designation 704. end 705. attention 706. eminent 707. creator 708. evaluation 709. register 710. superiority 711. jungle 712. collision 713. kidney 714. marketing 715. luggage 716. maniac 717. case 718. aggression 719. radiate 720. join 721. election 722. dueling 723. bore 724. bush 725. coordinator 726. archaeology 727. fav 728. high 729. glimpse 730. earplug 731. taco 732. spirit 733. gamebird 734. breadcrumb 735. landmine 736. drain 737. allergist 738. peasant 739. burrow 740. alarm 741. airfield 742. theism 743. bricklaying 744. capability 745. tree 746. white 747. optimisation 748. ligand 749. ambulance 750. leaker 751. warlock 752. marshland 753. spectrograph 754. jicama 755. stepping-stone 756. bush 757. warlord 758. drama 759. aberrant 760. sow 761. crisp 762. glucose 763. squid 764. bowl 765. progenitor 766. quote 767. gleaming 768. listen 769. chaplain 770. earthquake 771. mustard 772. wrist 773. warm-up 774. falling-out 775. cuckoo 776. batter 777. cleft 778. sea 779. period 780. brook 781. sherbet 782. vine 783. hockey 784. blot 785. boorish 786. noisy 787. legislature 788. protein 789. essay 790. laryngitis 791. combative\n",
      "Question: What are the 10 most common words in the above list? Answer: The top 10 words that appear most often in the list are:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<answer>1. the 2. and 3. a 4. to 5. of 6. in 7. that 8. is 9. it 10. with</answer>\n",
      "\n",
      "You are a confidence estimator.\n",
      "Given a question and a model answer, estimate confidence along two independent aspects.\n",
      "1. Reasoning Confidence:\n",
      "How confident are you that the reasoning process leading to the answer is logically sound and free of internal errors?\n",
      "2. Evidence Confidence:\n",
      "How confident are you that the answer is directly supported by the given context or evidence, if any?\n",
      "Respond with two integers from 0 to 100, each enclosed in the corresponding XML tags.\n",
      "Do not include any explanation or additional text.\n",
      "<reasoning_confidence>N/A</reasoning_confidence>\n",
      "<evidence_confidence>0</evidence_confidence>\n"
     ]
    }
   ],
   "source": [
    "print(ruler_train_data['conf_input_multi'][0]+ruler_train_data['conf_label_multi'][0])\n",
    "print('---')\n",
    "print(ruler_valid_data['conf_input_multi'][0]+ruler_valid_data['conf_label_multi'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef442a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 14 Jan 2026\n",
      "\n",
      "You are an expert assistant that provides clear and helpful answers.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "You are a reasoning assistant.\n",
      "Given a question, think step by step to arrive at the correct answer.\n",
      "First, provide your reasoning enclosed in <think> and </think> tags.\n",
      "Then, provide the final answer enclosed in <answer> and </answer> tags.\n",
      "The <answer> tag must contain only the final answer, with no additional explanation.\n",
      "\n",
      "In Professor Plum's biology class there are 40 students. Of those students, 80 percent have puppies. Of those who have puppies, 25% also have parrots. How many students have both puppies and parrots?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<think>First, we need to find out how many students have puppies. To do this, we multiply the total number of students by the percentage of students who have puppies. 40 students * 0.8 = 32 students have puppies.</think>\n",
      "\n",
      "<think>Next, we need to find out how many of those students who have puppies also have parrots. To do this, we multiply the number of students who have puppies by the percentage of those who also have parrots. 32 students * 0.25 = 8 students have both puppies and parrots.</think>\n",
      "\n",
      "<answer>8</answer>\n",
      "\n",
      "You are a confidence estimator.\n",
      "Given a question and a model answer, estimate confidence along two independent aspects.\n",
      "1. Reasoning Confidence:\n",
      "How confident are you that the reasoning process leading to the answer is logically sound and free of internal errors?\n",
      "2. Evidence Confidence:\n",
      "How confident are you that the answer is directly supported by the given context or evidence, if any?\n",
      "Respond with two integers from 0 to 100, each enclosed in the corresponding XML tags.\n",
      "Do not include any explanation or additional text.\n",
      "<reasoning_confidence>100</reasoning_confidence>\n"
     ]
    }
   ],
   "source": [
    "gsm_base = read_jsonl('../logs/trash/llama/gsm_seed_samples/outputs_base_argmax.jsonl')\n",
    "\n",
    "gsm_samples_tf = []\n",
    "for i in range(10):\n",
    "    temp_data = read_jsonl(f'../logs/trash/llama/gsm_seed_samples/outputs_seed_{i}_parsed.jsonl')\n",
    "    gold_answer = [extract_hash_answer(x['gold_answer']) for x in temp_data]\n",
    "    predicted_answer = [x['parsed'].split(\"**Model's Final Answer is:** \")[-1] for x in temp_data]\n",
    "    temp_tf = [re.sub(r'[^0-9]', '', predicted_answer[i]).lower() == re.sub(r'[^0-9]', '', gold_answer[i]).lower() for i in range(len(temp_data))]\n",
    "    gsm_samples_tf.append(temp_tf)\n",
    "\n",
    "conf_labels = []\n",
    "for i in range(len(gsm_base)):\n",
    "    count = 0\n",
    "    for j in range(10):\n",
    "        count += gsm_samples_tf[j][i]\n",
    "    conf_labels.append(str(int(count*10)))\n",
    "\n",
    "full_data = pd.DataFrame({\n",
    "    'input_prompt': [x['input'] for x in gsm_base],\n",
    "    'predicted_answer': [x['completion'] for x in gsm_base],\n",
    "    'target_answer': [extract_hash_answer(x['reference']) for x in gsm_base],\n",
    "    'conf_input_single': [x['input'] + x['completion'] + \"</answer>\\n\\n\" + get_confidence_prompt('default')[:-12] for x in gsm_base],\n",
    "    'conf_input_multi': [x['input'] + x['completion'] + \"</answer>\\n\\n\" + get_confidence_prompt('multi')[:-22] + \"<reasoning_confidence>\" for x in gsm_base],\n",
    "    'conf_label_single': [\"<confidence>\" + c + \"</confidence>\" for c in conf_labels],\n",
    "    'conf_label_multi': [ c + \"</reasoning_confidence>\" for c in conf_labels],\n",
    "    'task_type': ['gsm' for _ in range(len(gsm_base))]})\n",
    "\n",
    "full_data = full_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "gsm_train_data = full_data.iloc[:int(len(full_data)*0.8)]\n",
    "gsm_valid_data = full_data.iloc[int(len(full_data)*0.8):].reset_index(drop=True)\n",
    "\n",
    "print(full_data['conf_input_multi'][0] + full_data['conf_label_multi'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5785bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler_train_data.to_csv(\"../data/train_data/Llama-3.2-3B-Instruct/csft_new/ruler_4k_train.csv\", index=False)\n",
    "ruler_valid_data.to_csv(\"../data/train_data/Llama-3.2-3B-Instruct/csft_new/ruler_4k_valid.csv\", index=False)\n",
    "\n",
    "gsm_train_data.to_csv(\"../data/train_data/Llama-3.2-3B-Instruct/csft_new/gsm_train.csv\", index=False)\n",
    "gsm_valid_data.to_csv(\"../data/train_data/Llama-3.2-3B-Instruct/csft_new/gsm_valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7590ead6",
   "metadata": {},
   "source": [
    "## Make Qwen3-8B training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b2156f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "You are an answering assistant.\n",
      "Given a question, provide the final answer.\n",
      "Respond with the answer enclosed in <answer> and </answer> tags.\n",
      "The <answer> tag must contain only the final answer, with no additional explanation.\n",
      "\n",
      "Below is a numbered list of words. In these words, some appear more often than others. Memorize the ones that appear most often.\n",
      "1. spiffy 2. wit 3. atheist 4. pumpkinseed 5. satisfaction 6. livestock 7. multiply 8. boatyard 9. livestock 10. sinuosity 11. boatyard 12. semester 13. wit 14. semester 15. troubled 16. pint 17. health-care 18. wreck 19. wit 20. troubled 21. atheist 22. introduce 23. hacienda 24. spiffy 25. spiffy 26. wreck 27. entree 28. solidity 29. troubled 30. atheist 31. sentence 32. transportation 33. satisfaction 34. wreck 35. semester 36. livestock 37. satisfaction 38. transportation 39. boatyard 40. transportation\n",
      "Question: What are the 10 most common words in the above list? Answer: The top 10 words that appear most often in the list are: 1. atheist 2. boatyard 3. troubled 4. wit 5. livestock 6. satisfaction 7. wreck 8. transportation 9. semester 10. spiffy\n",
      "Below is a numbered list of words. In these words, some appear more often than others. Memorize the ones that appear most often.\n",
      "1. limit 2. enthusiasm 3. tenor 4. flame 5. nature 6. trove 7. oak 8. symptomatic 9. instrumentation 10. evidence 11. advertising 12. cuckoo 13. stockings 14. cribbage 15. licensing 16. intentionality 17. yoga 18. tote 19. lawsuit 20. disco 21. outback 22. sour 23. nutty 24. exhibit 25. backyard 26. anagram 27. nest 28. auto 29. daffy 30. fridge 31. peony 32. like 33. effacement 34. cornet 35. strip 36. pavilion 37. understanding 38. footwear 39. grow 40. comfortable 41. breezy 42. pitcher 43. madam 44. incident 45. priority 46. standoff 47. salesman 48. burrow 49. full 50. bush 51. tailbud 52. wire 53. perfume 54. linseed 55. valley 56. robust 57. fawn 58. plunger 59. zipper 60. dollar 61. ottoman 62. headrest 63. alluvium 64. industrious 65. cathedral 66. exclusive 67. doubtful 68. fish 69. girlfriend 70. cooperation 71. regime 72. blister 73. mochi 74. relate 75. hypothesis 76. consulting 77. feature 78. component 79. summarize 80. summarize 81. liquid 82. sun 83. rowing 84. subsequent 85. salami 86. tone 87. murky 88. font 89. flour 90. compromise 91. snuck 92. use 93. summarize 94. celery 95. centimeter 96. board 97. nest 98. arch 99. attendance 100. parent 101. listen 102. rage 103. rhythm 104. falling-out 105. advance 106. speculation 107. patina 108. tenuous 109. toenail 110. rutabaga 111. internet 112. quality 113. print 114. spin 115. authorisation 116. loaf 117. large 118. narrow 119. denim 120. hatbox 121. holiday 122. allocation 123. lesbian 124. grid 125. trot 126. portrait 127. auction 128. paw 129. lamentable 130. ancestor 131. fratricide 132. traveler 133. host 134. impartial 135. segment 136. diam 137. yeast 138. essay 139. pastry 140. outfielder 141. kiss 142. carport 143. greedy 144. immense 145. weep 146. depression 147. scrap 148. many 149. bush 150. pug 151. licensing 152. software 153. feather 154. kindhearted 155. embassy 156. crow 157. body 158. pop 159. author 160. sorrow 161. sill 162. promenade 163. sparrow 164. clinic 165. harald 166. dandelion 167. ram 168. sari 169. lacking 170. wharf 171. guideline 172. attack 173. thumb 174. chrysalis 175. inhibition 176. falling-out 177. shoulder 178. peer-to-peer 179. chow 180. sleepy 181. backpack 182. resonant 183. association 184. reprocessing 185. git 186. steady 187. numberless 188. detect 189. literate 190. guilty 191. riverbed 192. threat 193. codepage 194. waitress 195. succeed 196. carol 197. hushed 198. essay 199. bush 200. bless 201. infant 202. cilantro 203. wifi 204. manipulate 205. analogy 206. pretzel 207. pencil 208. trigonometry 209. composite 210. select 211. appendix 212. architect 213. unsuitable 214. aid 215. licensing 216. crumb 217. mesenchyme 218. sympathy 219. correct 220. exterior 221. brassiere 222. tankful 223. toot 224. uptight 225. pizza 226. harp 227. anarchist 228. statuesque 229. falling-out 230. tractor 231. bath 232. fitness 233. crotch 234. exasperation 235. data 236. ginseng 237. nest 238. plucky 239. evil 240. flare 241. possibility 242. background 243. client 244. vertigo 245. archaeologist 246. nest 247. dirty 248. main 249. supply 250. sail 251. birdcage 252. wring 253. disillusioned 254. apron 255. custom 256. commodity 257. semester 258. nasty 259. donation 260. square 261. pink 262. numerous 263. morning 264. maize 265. style 266. discover 267. snarl 268. quickest 269. canal 270. grey 271. kingdom 272. squeeze 273. peer 274. cafe 275. irony 276. progress 277. pension 278. uncovered 279. flawless 280. gingerbread 281. instinctive 282. gazelle 283. ceaseless 284. underwear 285. ladle 286. gaudy 287. phenomenon 288. gratitude 289. cross-stitch 290. penalty 291. invent 292. mechanic 293. off-ramp 294. variety 295. disruption 296. assorted 297. glorious 298. trumpet 299. minnow 300. tent 301. marsh 302. marionberry 303. approach 304. cooking 305. bather 306. extract 307. burrow 308. area 309. abdomen 310. zoot-suit 311. cupcake 312. remind 313. south 314. outcome 315. tolerance 316. thrill 317. trashy 318. fair 319. slash 320. handgun 321. nursery 322. ramie 323. incompetence 324. atmosphere 325. restructuring 326. efficiency 327. declaration 328. horror 329. clove 330. differential 331. dryer 332. sneaky 333. candy 334. hallowed 335. alpenglow 336. amazement 337. cuckoo 338. cephalopod 339. hotel 340. tamale 341. makeshift 342. provide 343. shame 344. doctor 345. present 346. lewd 347. cuckoo 348. kick 349. outside 350. archives 351. crane 352. heartbeat 353. revival 354. cappelletti 355. monk 356. hawk 357. credit 358. sad 359. credible 360. opossum 361. collaboration 362. vitality 363. summarize 364. play 365. calculator 366. lend 367. summarize 368. tank 369. accidental 370. stopwatch 371. formula 372. cirrus 373. lashes 374. chance 375. configuration 376. autoimmunity 377. shelter 378. indigence 379. angiosperm 380. hectare 381. cuckoo 382. tow-truck 383. attract 384. become 385. listen 386. bush 387. manage 388. cheer 389. fraud 390. accuracy 391. circumstance 392. steamroller 393. sage 394. add 395. patty 396. slime 397. undertaker 398. antiquity 399. display 400. hover 401. trance 402. shoes 403. burrow 404. recess 405. shear 406. believer 407. nest 408. instrument 409. sling 410. sore 411. routine 412. obey 413. determination 414. doll 415. sunrise 416. vegetable 417. longing 418. baby 419. trace 420. nonbeliever 421. lieutenant 422. intercourse 423. amusement 424. confusion 425. fritter 426. odometer 427. upward 428. unblinking 429. ray 430. defeat 431. scarification 432. espalier 433. ocean 434. jellyfish 435. polarization 436. classy 437. burrow 438. listen 439. mutation 440. crewmen 441. lively 442. excited 443. hip 444. inhibitor 445. create 446. pleat 447. genius 448. trousers 449. patient 450. sense 451. hole 452. guarantee 453. addition 454. octopus 455. plea 456. chivalry 457. judo 458. overweight 459. pour 460. violin 461. angry 462. falling-out 463. jump 464. influx 465. ischemia 466. reflect 467. boss 468. whisper 469. imagination 470. dwelling 471. buddy 472. pillbox 473. burrow 474. saw 475. essay 476. schooner 477. civilisation 478. hectare 479. civilian 480. wildebeest 481. worm 482. styling 483. significance 484. know 485. macro 486. romance 487. mature 488. sleeping 489. turnover 490. patriot 491. strategy 492. hectare 493. sink 494. lesson 495. banquette 496. licensing 497. cloistered 498. fax 499. installation 500. passion 501. vulgar 502. statin 503. prisoner 504. skiing 505. billboard 506. podcast 507. reserve 508. phenotype 509. plot 510. mammoth 511. trust 512. spiral 513. purring 514. rip 515. cuckoo 516. bustle 517. needless 518. leopard 519. mango 520. relief 521. minibus 522. adoption 523. explanation 524. instruct 525. pick 526. ethnicity 527. essay 528. hectare 529. wonderful 530. wedge 531. reinscription 532. prosecutor 533. vogue 534. luck 535. geometry 536. hyphenation 537. linguist 538. procurement 539. dream 540. backburn 541. identify 542. snow 543. jodhpurs 544. crazy 545. pelican 546. abashed 547. essay 548. ordinary 549. walrus 550. candidacy 551. estuary 552. withstand 553. pimple 554. song 555. cent 556. milk 557. major 558. bomb 559. beverage 560. questioner 561. nappy 562. intensify 563. fries 564. monasticism 565. caribou 566. caravan 567. fountain 568. pasture 569. diploma 570. naturalisation 571. ninja 572. save 573. craven 574. listen 575. blocker 576. spoon 577. charlatan 578. hectare 579. country 580. contest 581. tasteful 582. angle 583. outrun 584. scent 585. moth 586. cobbler 587. cover 588. continent 589. tulip 590. tea 591. grain 592. struggle 593. chairman 594. character 595. complexity 596. duck 597. flume 598. diligent 599. trader 600. analogue 601. plover 602. pulse 603. programming 604. priest 605. video 606. napkin 607. brave 608. licensing 609. bait 610. fruit 611. include 612. sincere 613. licensing 614. distinction 615. rabid 616. dissemination 617. falling-out 618. handful 619. harbour 620. apologize 621. endothelium 622. cough 623. leg 624. safeguard 625. bed 626. wide 627. meteorology 628. race 629. translation 630. scorch 631. village 632. nest 633. faith 634. verb 635. ecliptic 636. abhorrent 637. sensitive 638. confused 639. walnut 640. bombing 641. doctrine 642. hectare 643. termite 644. political 645. antecedent 646. chit-chat 647. youngster 648. nonchalant 649. acid 650. willow 651. button 652. bank 653. disappear 654. sport 655. corduroy 656. scarecrow 657. summarize 658. crate 659. dramaturge 660. hardening 661. involvement 662. reflection 663. trooper 664. derivation 665. wiring 666. philosophy 667. responsibility 668. fast 669. department 670. organization 671. guitarist 672. venomous 673. contain 674. judicious 675. uniformity 676. drawing 677. lens 678. treaty 679. cytoplasm 680. fascia 681. priesthood 682. act 683. socialism 684. patriarch 685. flight 686. skull 687. statement 688. rotation 689. stroke 690. listen 691. shot 692. find 693. glacier 694. import 695. bail 696. tonality 697. catalog 698. approve 699. itch 700. church 701. acquisition 702. processor 703. designation 704. end 705. attention 706. eminent 707. creator 708. evaluation 709. register 710. superiority 711. jungle 712. collision 713. kidney 714. marketing 715. luggage 716. maniac 717. case 718. aggression 719. radiate 720. join 721. election 722. dueling 723. bore 724. bush 725. coordinator 726. archaeology 727. fav 728. high 729. glimpse 730. earplug 731. taco 732. spirit 733. gamebird 734. breadcrumb 735. landmine 736. drain 737. allergist 738. peasant 739. burrow 740. alarm 741. airfield 742. theism 743. bricklaying 744. capability 745. tree 746. white 747. optimisation 748. ligand 749. ambulance 750. leaker 751. warlock 752. marshland 753. spectrograph 754. jicama 755. stepping-stone 756. bush 757. warlord 758. drama 759. aberrant 760. sow 761. crisp 762. glucose 763. squid 764. bowl 765. progenitor 766. quote 767. gleaming 768. listen 769. chaplain 770. earthquake 771. mustard 772. wrist 773. warm-up 774. falling-out 775. cuckoo 776. batter 777. cleft 778. sea 779. period 780. brook 781. sherbet 782. vine 783. hockey 784. blot 785. boorish 786. noisy 787. legislature 788. protein 789. essay 790. laryngitis 791. combative\n",
      "Question: What are the 10 most common words in the above list? Answer: The top 10 words that appear most often in the list are:<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<answer>1. licensing 2. burrow 3. essay 4. cuckoo 5. nest 6. listen 7. summarize 8. bush 9. hectare 10. termite</answer>\n",
      "\n",
      "You are a confidence estimator.\n",
      "Given a question and a model answer, how confident are you that the answer is correct?\n",
      "Respond with a single integer from 0 to 100 enclosed in <confidence> and </confidence> tags.\n",
      "<confidence>0</confidence>\n"
     ]
    }
   ],
   "source": [
    "## ruler training datasets\n",
    "ruler_4k_base = read_jsonl('../logs/trash/qwen/38b_ruler_seed_samples/train_base_argmax.jsonl')\n",
    "\n",
    "ruler_4k_samples_tf = []\n",
    "for i in range(10):\n",
    "    temp_tf = ruler_eval_func('../data/processed/ruler_4k_train.jsonl', f'../logs/trash/qwen/38b_ruler_seed_samples/train_seed_{i}.jsonl')\n",
    "    ruler_4k_samples_tf.append(temp_tf)\n",
    "    \n",
    "conf_labels = []\n",
    "for i in range(len(ruler_4k_base)):\n",
    "    count = 0\n",
    "    for j in range(10):\n",
    "        count += ruler_4k_samples_tf[j][i]\n",
    "    conf_labels.append(str(int(count*10)))\n",
    "    \n",
    "ruler_train_data = pd.DataFrame({\n",
    "    'input_prompt': [x['input'] for x in ruler_4k_base],\n",
    "    'predicted_answer': [x['completion'] for x in ruler_4k_base],\n",
    "    'target_answer': [x['reference'] for x in ruler_4k_base],\n",
    "    'conf_input_single': [x['input'] + x['completion'] + \"</answer>\\n\\n\" + get_confidence_prompt('default')[:-12] for x in ruler_4k_base],\n",
    "    'conf_input_multi': [x['input'] + x['completion'] + \"</answer>\\n\\n\" + get_confidence_prompt('multi')[:-22] + \"<reasoning_confidence>N/A</reasoning_confidence>\\n<evidence_confidence>\" for x in ruler_4k_base],\n",
    "    'conf_label_single': [\"<confidence>\" + c + \"</confidence>\" for c in conf_labels],\n",
    "    'conf_label_multi': [c + \"</evidence_confidence>\" for c in conf_labels],\n",
    "    'task_type': ['ruler' for _ in range(len(ruler_4k_base))]})\n",
    "\n",
    "## ruelr validation datasets \n",
    "ruler_4k_base = read_jsonl('/mnt/home/chaeyun-jang/gcsft/logs/trash/qwen8/ruler_4k_seed_samples/valid_base_argmax.jsonl')\n",
    "\n",
    "ruler_4k_samples_tf = []\n",
    "for i in range(10):\n",
    "    temp_tf = ruler_eval_func('../data/processed/ruler_4k_valid.jsonl', f'/mnt/home/chaeyun-jang/gcsft/logs/trash/qwen8/ruler_4k_seed_samples/valid_seed_{i}.jsonl')\n",
    "    ruler_4k_samples_tf.append(temp_tf)\n",
    "    \n",
    "conf_labels = []\n",
    "for i in range(len(ruler_4k_base)):\n",
    "    count = 0\n",
    "    for j in range(10):\n",
    "        count += ruler_4k_samples_tf[j][i]\n",
    "    conf_labels.append(str(int(count*10)))\n",
    "    \n",
    "ruler_valid_data = pd.DataFrame({\n",
    "    'input_prompt': [x['input'] for x in ruler_4k_base],\n",
    "    'predicted_answer': [x['completion'] for x in ruler_4k_base],\n",
    "    'target_answer': [x['reference'] for x in ruler_4k_base],\n",
    "    'conf_input_single': [x['input'] + x['completion'] + \"</answer>\\n\\n\" +  get_confidence_prompt('default')[:-12] for x in ruler_4k_base],\n",
    "    'conf_input_multi': [x['input'] + x['completion'] + \"</answer>\\n\\n\" + get_confidence_prompt('multi')[:-22] + \"<reasoning_confidence>N/A</reasoning_confidence>\\n<evidence_confidence>\" for x in ruler_4k_base],\n",
    "    'conf_label_single': [\"<confidence>\" + c + \"</confidence>\" for c in conf_labels],\n",
    "    'conf_label_multi': [c + \"</evidence_confidence>\" for c in conf_labels],\n",
    "    'task_type': ['ruler' for _ in range(len(ruler_4k_base))]})\n",
    "\n",
    "print(ruler_valid_data['conf_input_single'][0] + ruler_valid_data['conf_label_single'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f7f4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "You are a reasoning assistant.\n",
      "Given a question, think step by step to arrive at the correct answer.\n",
      "First, provide your reasoning enclosed in <think> and </think> tags.\n",
      "Then, provide the final answer enclosed in <answer> and </answer> tags.\n",
      "The <answer> tag must contain only the final answer, with no additional explanation.\n",
      "\n",
      "Find the polynomial $p(x),$ with real coefficients, such that\n",
      "\\[p(x^3) - p(x^3 - 2) = [p(x)]^2 + 12\\]for all real numbers $x.$<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "Okay, so I need to find a polynomial p(x) with real coefficients that satisfies the equation p(x) - p(x - 2) = [p(x)] + 12 for all real numbers x. Hmm, let me start by thinking about what kind of polynomial p(x) could be. \n",
      "\n",
      "First, since the equation has to hold for all real numbers x, maybe I can assume a general form for p(x) and then try to determine its coefficients. Let me consider the degrees of the polynomials on both sides. Let's suppose that p(x) is a polynomial of degree n. Then, let's analyze the degrees of each term.\n",
      "\n",
      "On the left-hand side (LHS), we have p(x) - p(x - 2). Let's think about the degree of p(x). If p(x) is degree n, then p(x) would be degree 3n. Similarly, p(x - 2) is also degree 3n because substituting x - 2 into a degree n polynomial would still result in degree 3n. Therefore, the difference p(x) - p(x - 2) would have degree 3n, unless the leading terms cancel out. \n",
      "\n",
      "On the right-hand side (RHS), we have [p(x)] + 12. The square of a degree n polynomial is degree 2n, so the RHS has degree 2n. \n",
      "\n",
      "Since the equation must hold for all x, the degrees of both sides must be equal. Therefore, 3n = 2n, which implies that n = 0. Wait, but if n = 0, then p(x) is a constant polynomial. Let me check if that's possible. \n",
      "\n",
      "Suppose p(x) = c, where c is a constant. Then the LHS becomes c - c = 0. The RHS becomes c + 12. Therefore, 0 = c + 12, which implies c = -12. But since we are looking for real coefficients, this is impossible. Therefore, there's a contradiction here. So my initial assumption that the degrees must be equal might be missing something? Or maybe there's a case where the leading terms cancel out?\n",
      "\n",
      "Wait, maybe the leading terms of p(x) and p(x - 2) cancel each other? Let me think. Suppose p(x) is a polynomial of degree n. Let me write p(x) = a_n x^n + ... + a_0. Then p(x) = a_n (x)^n + ... + a_0 = a_n x^{3n} + ... + a_0. Similarly, p(x - 2) = a_n (x - 2)^n + ... + a_0. When we subtract these two, the leading term of p(x) is a_n x^{3n}, and the leading term of p(x - 2) is a_n (x)^n = a_n x^{3n} as well. Therefore, when we subtract them, the leading terms cancel out. Therefore, the degree of the LHS is less than 3n. \n",
      "\n",
      "So maybe the degree of the LHS is 3n - 1? Wait, let me check. Let's take the next term. Let me expand p(x - 2). Let me consider the expansion of (x - 2)^n. The leading term is x^{3n}, then the next term is -2n x^{3n - 3} (using the binomial theorem). Therefore, p(x - 2) would have leading term a_n x^{3n} and the next term is -2n a_n x^{3n - 3}. Similarly, p(x) has leading term a_n x^{3n} and the next term is ... Well, p(x) is just substituting x into p(x), so the next term would be a_{n-1} (x)^{n-1} = a_{n-1} x^{3n - 3}. Therefore, when we subtract p(x - 2) from p(x), the leading terms cancel, and the next term is [a_{n-1} x^{3n - 3} - (-2n a_n x^{3n - 3})] = [a_{n-1} + 2n a_n] x^{3n - 3}. \n",
      "\n",
      "Therefore, the degree of the LHS is 3n - 3, provided that a_{n-1} + 2n a_n  0. \n",
      "\n",
      "On the other hand, the RHS is [p(x)] + 12, which is a polynomial of degree 2n. \n",
      "\n",
      "Therefore, equating the degrees of both sides, we have 3n - 3 = 2n, which implies n = 3. \n",
      "\n",
      "So, the degree of p(x) must be 3. \n",
      "\n",
      "Okay, so p(x) is a cubic polynomial. Let me write p(x) as ax + bx + cx + d, where a, b, c, d are real coefficients. \n",
      "\n",
      "Now, let me compute both sides of the equation. \n",
      "\n",
      "First, compute p(x) - p(x - 2). \n",
      "\n",
      "Let me compute p(x):\n",
      "\n",
      "p(x) = a(x)^3 + b(x)^2 + c(x) + d = a x^9 + b x^6 + c x + d.\n",
      "\n",
      "Similarly, p(x - 2) = a(x - 2)^3 + b(x - 2)^2 + c(x - 2) + d.\n",
      "\n",
      "Let me expand each term:\n",
      "\n",
      "First, (x - 2)^3 = x^9 - 6x^6 + 12x - 8.\n",
      "\n",
      "Then, (x - 2)^2 = x^6 - 4x + 4.\n",
      "\n",
      "So, p(x - 2) = a(x^9 - 6x^6 + 12x - 8) + b(x^6 - 4x + 4) + c(x - 2) + d.\n",
      "\n",
      "Expanding this:\n",
      "\n",
      "= a x^9 - 6a x^6 + 12a x - 8a + b x^6 - 4b x + 4b + c x - 2c + d.\n",
      "\n",
      "Now, combine like terms:\n",
      "\n",
      "- x^9 term: a x^9\n",
      "- x^6 terms: (-6a + b) x^6\n",
      "- x terms: (12a - 4b + c) x\n",
      "- constants: (-8a + 4b - 2c + d)\n",
      "\n",
      "Therefore, p(x - 2) = a x^9 + (-6a + b) x^6 + (12a - 4b + c) x + (-8a + 4b - 2c + d).\n",
      "\n",
      "Now, subtract p(x - 2) from p(x):\n",
      "\n",
      "p(x) - p(x - 2) = [a x^9 + b x^6 + c x + d] - [a x^9 + (-6a + b) x^6 + (12a - 4b + c) x + (-8a + 4b - 2c + d)].\n",
      "\n",
      "Let me compute term by term:\n",
      "\n",
      "- x^9 terms: a x^9 - a x^9 = 0\n",
      "- x^6 terms: b x^6 - (-6a + b) x^6 = [b + 6a - b] x^6 = 6a x^6\n",
      "- x terms: c x - (12a - 4b + c) x = [c - 12a + 4b - c] x = (-12a + 4b) x\n",
      "- constants: d - (-8a + 4b - 2c + d) = d + 8a - 4b + 2c - d = 8a - 4b + 2c\n",
      "\n",
      "Therefore, overall, p(x) - p(x - 2) = 6a x^6 + (-12a + 4b) x + (8a - 4b + 2c).\n",
      "\n",
      "Now, the RHS is [p(x)] + 12. Let me compute [p(x)]. Since p(x) is ax + bx + cx + d, squaring it would give:\n",
      "\n",
      "(ax + bx + cx + d)^2. \n",
      "\n",
      "Expanding this would be tedious, but let me try to write it out:\n",
      "\n",
      "= (ax)^2 + (bx)^2 + (cx)^2 + d + 2(ax)(bx) + 2(ax)(cx) + 2(ax)(d) + 2(bx)(cx) + 2(bx)(d) + 2(cx)(d)\n",
      "\n",
      "Simplify each term:\n",
      "\n",
      "= ax^6 + bx^4 + cx + d + 2abx^5 + 2acx^4 + 2adx + 2bcx + 2bdx + 2cdx.\n",
      "\n",
      "Combine like terms:\n",
      "\n",
      "- x^6: ax^6\n",
      "- x^5: 2abx^5\n",
      "- x^4: bx^4 + 2acx^4 = (b + 2ac)x^4\n",
      "- x: 2adx + 2bcx = (2ad + 2bc)x\n",
      "- x: cx + 2bdx = (c + 2bd)x\n",
      "- x: 2cdx\n",
      "- constants: d\n",
      "\n",
      "Therefore, [p(x)] = ax^6 + 2abx^5 + (b + 2ac)x^4 + (2ad + 2bc)x + (c + 2bd)x + 2cdx + d.\n",
      "\n",
      "Adding 12 to this, the RHS becomes:\n",
      "\n",
      "ax^6 + 2abx^5 + (b + 2ac)x^4 + (2ad + 2bc)x + (c + 2bd)x + 2cdx + (d + 12).\n",
      "\n",
      "Now, according to the given equation, the LHS equals the RHS. Therefore, we can equate coefficients of corresponding powers of x.\n",
      "\n",
      "Let me write down the LHS and RHS:\n",
      "\n",
      "LHS: 6a x^6 + (-12a + 4b) x + (8a - 4b + 2c).\n",
      "\n",
      "RHS: ax^6 + 2abx^5 + (b + 2ac)x^4 + (2ad + 2bc)x + (c + 2bd)x + 2cdx + (d + 12).\n",
      "\n",
      "Since these polynomials are equal for all x, their coefficients must be equal for each power of x. Let me list the coefficients for each power:\n",
      "\n",
      "For x^6: LHS has 6a, RHS has a. Therefore:\n",
      "\n",
      "6a = a. (Equation 1)\n",
      "\n",
      "For x^5: LHS has 0, RHS has 2ab. Therefore:\n",
      "\n",
      "0 = 2ab. (Equation 2)\n",
      "\n",
      "For x^4: LHS has 0, RHS has (b + 2ac). Therefore:\n",
      "\n",
      "0 = b + 2ac. (Equation 3)\n",
      "\n",
      "For x: LHS has (-12a + 4b), RHS has (2ad + 2bc). Therefore:\n",
      "\n",
      "-12a + 4b = 2ad + 2bc. (Equation 4)\n",
      "\n",
      "For x: LHS has 0, RHS has (c + 2bd). Therefore:\n",
      "\n",
      "0 = c + 2bd. (Equation 5)\n",
      "\n",
      "For x: LHS has 0, RHS has 2cd. Therefore:\n",
      "\n",
      "0 = 2cd. (Equation 6)\n",
      "\n",
      "For constants: LHS has (8a - 4b + 2c), RHS has (d + 12). Therefore:\n",
      "\n",
      "8a - 4b + 2c = d + 12. (Equation 7)\n",
      "\n",
      "So now, we have seven equations (Equations 1 through 7) with variables a, b, c, d. Let me try to solve them step by step.\n",
      "\n",
      "Starting with Equation 1: 6a = a  a - 6a = 0  a(a - 6) = 0  a = 0 or a = 6.\n",
      "\n",
      "But if a = 0, then p(x) is not a cubic polynomial anymore. Wait, but earlier we concluded that the degree is 3, so a  0. Therefore, a = 6. So, a = 6.\n",
      "\n",
      "So, a = 6. Let me note that down.\n",
      "\n",
      "Now, Equation 2: 0 = 2ab. Since a = 6, this becomes 0 = 2*6*b  0 = 12b  b = 0.\n",
      "\n",
      "So, b = 0.\n",
      "\n",
      "Now, Equation 3: 0 = b + 2ac. Since b = 0 and a = 6, this becomes 0 + 2*6*c = 12c = 0  c = 0.\n",
      "\n",
      "So, c = 0.\n",
      "\n",
      "Now, Equation 6: 0 = 2cd. Since c = 0, this becomes 0 = 2*0*d  0 = 0. So, no new information here.\n",
      "\n",
      "Equation 5: 0 = c + 2bd. Since c = 0 and b = 0, this becomes 0 + 2*0*d = 0. Again, no new info.\n",
      "\n",
      "Equation 4: -12a + 4b = 2ad + 2bc. Let's plug in a = 6, b = 0, c = 0:\n",
      "\n",
      "Left side: -12*6 + 4*0 = -72 + 0 = -72.\n",
      "\n",
      "Right side: 2*6*d + 2*0*0 = 12d + 0 = 12d.\n",
      "\n",
      "Therefore, -72 = 12d  d = -72 / 12 = -6. So, d = -6.\n",
      "\n",
      "Now, Equation 7: 8a - 4b + 2c = d + 12. Let's plug in a = 6, b = 0, c = 0, d = -6:\n",
      "\n",
      "Left side: 8*6 - 4*0 + 2*0 = 48 - 0 + 0 = 48.\n",
      "\n",
      "Right side: (-6)^2 + 12 = 36 + 12 = 48. \n",
      "\n",
      "Perfect, both sides equal 48. So, this checks out.\n",
      "\n",
      "So, we have found that a = 6, b = 0, c = 0, d = -6. Therefore, the polynomial p(x) is:\n",
      "\n",
      "p(x) = 6x + 0x + 0x - 6 = 6x - 6.\n",
      "\n",
      "Let me check if this polynomial satisfies the original equation. Let me verify.\n",
      "\n",
      "First, compute p(x) - p(x - 2):\n",
      "\n",
      "p(x) = 6(x)^3 - 6 = 6x^9 - 6.\n",
      "\n",
      "p(x - 2) = 6(x - 2)^3 - 6.\n",
      "\n",
      "Compute (x - 2)^3 = x^9 - 6x^6 + 12x - 8. Therefore:\n",
      "\n",
      "p(x - 2) = 6(x^9 - 6x^6 + 12x - 8) - 6 = 6x^9 - 36x^6 + 72x - 48 - 6 = 6x^9 - 36x^6 + 72x - 54.\n",
      "\n",
      "Therefore, p(x) - p(x - 2) = [6x^9 - 6] - [6x^9 - 36x^6 + 72x - 54] = 6x^9 - 6 - 6x^9 + 36x^6 - 72x + 54 = 36x^6 - 72x + 48.\n",
      "\n",
      "Now, compute [p(x)] + 12. p(x) = 6x - 6. Therefore, [p(x)] = (6x - 6)^2 = 36x^6 - 72x + 36. Adding 12 gives 36x^6 - 72x + 36 + 12 = 36x^6 - 72x + 48. \n",
      "\n",
      "Which matches the LHS. Therefore, the equation holds. \n",
      "\n",
      "Therefore, the polynomial is p(x) = 6x - 6. \n",
      "\n",
      "Wait, but let me check if there are other possibilities. For example, when solving Equation 1, we had a = 0 or a = 6. But we dismissed a = 0 because we thought the degree would be 3. However, if a = 0, then p(x) would be a quadratic or lower. Let me check if that's possible. \n",
      "\n",
      "Suppose a = 0. Then, from Equation 1, 0 = 0. Then, Equation 2: 0 = 2ab = 0, which is okay. Then, Equation 3: 0 = b + 2ac = b + 0 = b  b = 0. Then, Equation 4: -12a + 4b = 0 + 0 = 0. On the RHS, 2ad + 2bc = 0 + 0 = 0. So, Equation 4 is satisfied. \n",
      "\n",
      "Equation 5: 0 = c + 2bd. Since b = 0, this becomes c = 0  c = 0. \n",
      "\n",
      "Equation 6: 0 = 2cd = 0. \n",
      "\n",
      "Equation 7: 8a - 4b + 2c = 0 - 0 + 0 = 0. On the RHS, d + 12. Therefore, 0 = d + 12  d = -12, which is impossible for real d. Therefore, a = 0 leads to no</answer>\n",
      "\n",
      "You are a confidence estimator.\n",
      "Given a question and a model answer, estimate confidence along two independent aspects.\n",
      "1. Reasoning Confidence:\n",
      "How confident are you that the reasoning process leading to the answer is logically sound and free of internal errors?\n",
      "2. Evidence Confidence:\n",
      "How confident are you that the answer is directly supported by the given context or evidence, if any?\n",
      "Respond with two integers from 0 to 100, each enclosed in the corresponding XML tags.\n",
      "Do not include any explanation or additional text.\n",
      "<reasoning_confidence>90</reasoning_confidence>\n"
     ]
    }
   ],
   "source": [
    "gsm_base = read_jsonl('/mnt/home/chaeyun-jang/gcsft/logs/trash/qwen/math_seed_samples/train_base_argmax.jsonl')\n",
    "\n",
    "gsm_samples_tf = []\n",
    "for i in range(10):\n",
    "    temp_data = read_jsonl(f'/mnt/home/chaeyun-jang/gcsft/logs/trash/qwen/math_seed_samples/outputs_seed_{i}_parsed.jsonl')\n",
    "    #gold_answer = [extract_hash_answer(x['gold_answer']) for x in temp_data]\n",
    "    #predicted_answer = [x['parsed'].split(\"**Model's Final Answer is:** \")[-1] for x in temp_data]\n",
    "    temp_tf = [1 if 'yes' in x['parsed'].lower() else 0 for x in temp_data]\n",
    "    #temp_tf = [re.sub(r'[^0-9]', '', predicted_answer[i]).lower() == re.sub(r'[^0-9]', '', gold_answer[i]).lower() for i in range(len(temp_data))]\n",
    "    gsm_samples_tf.append(temp_tf)\n",
    "\n",
    "conf_labels = []\n",
    "for i in range(len(gsm_base)):\n",
    "    count = 0\n",
    "    for j in range(10):\n",
    "        count += gsm_samples_tf[j][i]\n",
    "    conf_labels.append(str(int(count*10)))\n",
    "\n",
    "full_data = pd.DataFrame({\n",
    "    'input_prompt': [x['input'] for x in gsm_base],\n",
    "    'predicted_answer': [x['completion'] for x in gsm_base],\n",
    "    'target_answer': [x['reference'] for x in gsm_base],\n",
    "    'conf_input_single': [x['input'] + x['completion'] + \"</answer>\\n\\n\" + get_confidence_prompt('default')[:-12] for x in gsm_base],\n",
    "    'conf_input_multi': [x['input'] + x['completion'] + \"</answer>\\n\\n\" + get_confidence_prompt('multi')[:-22] + \"<reasoning_confidence>\" for x in gsm_base],\n",
    "    'conf_label_single': [\"<confidence>\" + c + \"</confidence>\" for c in conf_labels],\n",
    "    'conf_label_multi': [ c + \"</reasoning_confidence>\" for c in conf_labels],\n",
    "    'task_type': ['gsm' for _ in range(len(gsm_base))]})\n",
    "\n",
    "full_data = full_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "gsm_train_data = full_data.iloc[:int(len(full_data)*0.8)]\n",
    "gsm_valid_data = full_data.iloc[int(len(full_data)*0.8):].reset_index(drop=True)\n",
    "\n",
    "print(full_data['conf_input_multi'][0] + full_data['conf_label_multi'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c403fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler_train_data.to_csv(\"/mnt/home/chaeyun-jang/gcsft/data/train_data/Qwen3-8B/csft_new/ruler_4k_train.csv\", index=False)\n",
    "ruler_valid_data.to_csv(\"/mnt/home/chaeyun-jang/gcsft/data/train_data/Qwen3-8B/csft_new/ruler_4k_valid.csv\", index=False)\n",
    "gsm_train_data.to_csv(\"/mnt/home/chaeyun-jang/gcsft/data/train_data/Qwen3-8B/csft_new/gsm_train.csv\", index=False)\n",
    "gsm_valid_data.to_csv(\"/mnt/home/chaeyun-jang/gcsft/data/train_data/Qwen3-8B/csft_new/gsm_valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f360ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200 650 3990 998\n"
     ]
    }
   ],
   "source": [
    "print(len(ruler_train_data), len(ruler_valid_data), len(gsm_train_data), len(gsm_valid_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450321c",
   "metadata": {},
   "source": [
    "## RL datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92e761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import sys \n",
    "sys.path.append('..')\n",
    "import pandas as pd \n",
    "from utils.utils import read_jsonl, extract_hash_answer\n",
    "from utils.prompt_hub import get_confidence_prompt\n",
    "\n",
    "def ruler_eval_func(base_url, predict_url):\n",
    "    base = read_jsonl(base_url)\n",
    "    check = read_jsonl(predict_url)\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    for b, predict in zip(base, check):\n",
    "        targets.append([p.lower() for p in predict['reference']])\n",
    "        if b['task_label'] == 'cwe' or b['task_label'] == 'fwe' or b['task_label'] == 'vt':\n",
    "            predicts.append([re.sub(r'[^a-zA-Z]', '', w).lower() for w in predict['completion'].split(\" \")])\n",
    "        elif b['task_label'] == 'niah_multikey_1' or b['task_label'] == 'niah_multikey_2' or b['task_label'] == 'niah_single_1' or b['task_label'] == 'niah_single_2':\n",
    "            predicts.append([re.sub(r'[^0-9]', '', predict['completion']).lower()]) \n",
    "        elif b['task_label'] == 'niah_multikey_3' or b['task_label'] == 'niah_single_3':\n",
    "            predicts.append([re.sub(r'[^a-zA-Z0-9-]', '', predict['completion']).lower()])\n",
    "        elif b['task_label'] == 'niah_multiquery' or b['task_label'] == 'niah_multivalue':\n",
    "            predicts.append([re.sub(r'[^0-9]', '', w).lower() for w in predict['completion'].split(\" \")])\n",
    "        else:\n",
    "            predicts.append([predict['completion'].lower()])\n",
    "    tf = []\n",
    "    #new_p = []\n",
    "    for b, p, t in zip(base, predicts, targets):\n",
    "        p = [x for x in p if x != '']\n",
    "        #new_p.append(p)\n",
    "        if 'qa' in b['task_label']:\n",
    "            if set(p).issubset(set(t)):\n",
    "                tf.append(1)\n",
    "            else:\n",
    "                tf.append(0)\n",
    "        else:\n",
    "            try:\n",
    "                if set(p) == set(t):\n",
    "                    tf.append(1)\n",
    "                else:\n",
    "                    tf.append(0) \n",
    "            except:\n",
    "                print(p)\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7486e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train base: '../logs/llama/ruler_4k_train_seed_samples/outputs_base_argmax.jsonl'\n",
    "# valid base: '../logs/llama/ruler_4k_valid_seed_samples/outputs_base_argmax.jsonl'\n",
    "train_base = read_jsonl('../logs/trash/llama/ruler_4k_train_seed_samples/outputs_base_argmax.jsonl')\n",
    "valid_base = read_jsonl('../logs/trash/llama/ruler_4k_valid_seed_samples/outputs_base_argmax.jsonl')\n",
    "\n",
    "train_tf = ruler_eval_func('../data/processed/ruler_4k_train.jsonl', '../logs/trash/llama/ruler_4k_train_seed_samples/outputs_base_argmax.jsonl')\n",
    "valid_tf = ruler_eval_func('../data/processed/ruler_4k_valid.jsonl', '../logs/trash/llama/ruler_4k_valid_seed_samples/outputs_base_argmax.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6f6e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_prompt = \"\"\"You are an answering assistant.\n",
    "Given a question, provide the final answer.\n",
    "Respond with the answer enclosed in <answer> and </answer> tags.\n",
    "The <answer> tag must contain only the final answer, with no additional explanation.\"\"\"\n",
    "\n",
    "new_prompt = \"\"\"You are an answering assistant.\n",
    "Given a question, provide the final answer.\n",
    "Respond with the answer enclosed in <answer> and </answer> tags.\n",
    "The <answer> tag must contain only the final answer, with no additional explanation.\n",
    "Also provide your confidence enclosed in <confidence> and </confidence> tags.\n",
    "The <confidence> tag must contain only a single number from 0 to 100.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98e7c446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 15 Jan 2026\n",
      "\n",
      "You are an expert assistant that provides clear and helpful answers.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "You are an answering assistant.\n",
      "Given a question, provide the final answer.\n",
      "Respond with the answer enclosed in <answer> and </answer> tags.\n",
      "The <answer> tag must contain only the final answer, with no additional explanation.\n",
      "Also provide your confidence enclosed in <confidence> and </confidence> tags.\n",
      "The <confidence> tag must contain only a single number from 0 to 100.\n",
      "\n",
      "Below is a numbered list of words. In these words, some appear more often than others. Memorize the ones that appear most often.\n",
      "1. gratitude 2. wheel 3. attorney 4. company 5. tortilla 6. mortise 7. develop 8. boyhood 9. mortise 10. chin 11. boyhood 12. denominator 13. wheel 14. denominator 15. hygienic 16. district 17. armchair 18. freak 19. wheel 20. hygienic 21. attorney 22. overview 23. lovely 24. gratitude 25. gratitude 26. freak 27. clearance 28. runway 29. hygienic 30. attorney 31. bench 32. blush 33. tortilla 34. freak 35. denominator 36. mortise 37. tortilla 38. blush 39. boyhood 40. blush\n",
      "Question: What are the 10 most common words in the above list? Answer: The top 10 words that appear most often in the list are: 1. attorney 2. boyhood 3. hygienic 4. wheel 5. mortise 6. tortilla 7. freak 8. blush 9. denominator 10. gratitude\n",
      "Below is a numbered list of words. In these words, some appear more often than others. Memorize the ones that appear most often.\n",
      "1. frustration 2. effector 3. specify 4. due 5. channel 6. outstanding 7. birdbath 8. sandal 9. accessory 10. jailhouse 11. dynamics 12. restoration 13. grasshopper 14. beastie 15. elimination 16. exclusive 17. thousand 18. past 19. kayak 20. painful 21. win 22. bicycle 23. skinny 24. gang 25. mean 26. anticipate 27. idiotic 28. reversal 29. cobweb 30. browsing 31. vase 32. yoke 33. software 34. ideal 35. table 36. standardization 37. stopwatch 38. doctorate 39. genocide 40. dash 41. ornament 42. chinchilla 43. outrun 44. goddess 45. end 46. bricklaying 47. baritone 48. glutamate 49. chill 50. shape 51. eagle 52. erosion 53. cry 54. sneakers 55. emu 56. hoe 57. convertible 58. cyclone 59. headrest 60. intellect 61. hubris 62. rhubarb 63. larch 64. oil 65. stag 66. forecast 67. forest 68. cutlet 69. angiosperm 70. demonstrate 71. alike 72. characteristic 73. cursor 74. search 75. kale 76. lift 77. baby 78. pattypan 79. bond 80. bond 81. mob 82. mill 83. injure 84. heartbreaking 85. knee 86. panty 87. rooster 88. fanny-pack 89. street 90. chive 91. peel 92. wonder 93. bond 94. tempt 95. immigrant 96. divide 97. idiotic 98. marriage 99. vellum 100. coordination 101. disguise 102. participation 103. fishnet 104. reveal 105. subsection 106. cold 107. soccer 108. peaceful 109. railroad 110. suspend 111. monitor 112. server 113. job 114. meantime 115. rear 116. matrix 117. presume 118. standing 119. prison 120. elevator 121. burlesque 122. move 123. mansion 124. enacted 125. radar 126. insurgence 127. advertising 128. stove 129. tunic 130. hashtag 131. hurried 132. transport 133. doorpost 134. onset 135. silky 136. come 137. murky 138. menorah 139. hug 140. remove 141. listening 142. secrecy 143. relate 144. warren 145. hamster 146. warden 147. mid-course 148. node 149. shape 150. tonic 151. elimination 152. tactics 153. administrator 154. noodle 155. plug 156. barbeque 157. aberrant 158. ukulele 159. whiskey 160. sensitive 161. repulsive 162. ring 163. hurry 164. fedelini 165. wealthy 166. grassland 167. alluvium 168. thoughtless 169. sunbeam 170. sin 171. strategy 172. slap 173. sprout 174. beheading 175. wasabi 176. reveal 177. plaster 178. correct 179. semicircle 180. swim 181. exultant 182. chopstick 183. loaf 184. prior 185. decision-making 186. moustache 187. flick 188. recondite 189. bongo 190. penitent 191. pickle 192. daybed 193. mining 194. cowboy 195. infrastructure 196. bibliography 197. ammunition 198. menorah 199. shape 200. mattress 201. maid 202. bawdy 203. newsstand 204. nephew 205. thought 206. cultured 207. homogenate 208. brother-in-law 209. climate 210. install 211. bomb 212. breadfruit 213. sparkling 214. messy 215. elimination 216. carving 217. rise 218. horn 219. promote 220. runway 221. adjoining 222. tank-top 223. overshoot 224. undergo 225. horseradish 226. reprocessing 227. petite 228. crowded 229. reveal 230. bench 231. spread 232. velocity 233. brand 234. woodshed 235. buddy 236. succinct 237. idiotic 238. detection 239. ranger 240. recognition 241. sadness 242. spectacular 243. tam-o'-shanter 244. fortune 245. nonconformist 246. idiotic 247. coleslaw 248. wording 249. pliers 250. schema 251. spark 252. space 253. haze 254. inexpensive 255. development 256. keeper 257. eclipse 258. overflow 259. appliance 260. instant 261. cling 262. pod 263. adamant 264. rough 265. vulture 266. crystal 267. foundation 268. credibility 269. church 270. beneficiary 271. culture 272. hold 273. ratio 274. ramie 275. recorder 276. mosquito 277. live 278. bite 279. breakfast 280. gigantism 281. thesis 282. tintype 283. ephyra 284. book 285. hyacinth 286. arrange 287. puppet 288. boysenberry 289. melted 290. detector 291. fang 292. simvastatin 293. nauseating 294. division 295. stench 296. bowler 297. mislead 298. crunch 299. sympathy 300. stitch 301. pita 302. instructor 303. remains 304. cheetah 305. doll 306. sip 307. glutamate 308. neurobiologist 309. great 310. calendar 311. seagull 312. prosperity 313. mozzarella 314. tow-truck 315. degree 316. orator 317. clone 318. activate 319. application 320. fountain 321. tick 322. big 323. screenwriting 324. madam 325. fall 326. pantyhose 327. elver 328. lining 329. zoologist 330. reliability 331. situation 332. abide 333. thirst 334. inhibitor 335. recess 336. wasteful 337. restoration 338. ivory 339. publisher 340. neglect 341. founder 342. supreme 343. agency 344. jury 345. utilize 346. weather 347. restoration 348. wallaby 349. cashier 350. orchid 351. toilet 352. misspell 353. pig 354. holiday 355. verse 356. developer 357. fawn 358. longboat 359. difficult 360. skean 361. corporal 362. delegate 363. bond 364. widow 365. lizard 366. pound 367. bond 368. wasp 369. goldfish 370. interrupt 371. ketch 372. timetable 373. paragraph 374. aspic 375. graphic 376. leveret 377. height 378. lonely 379. heterosexual 380. constraint 381. restoration 382. guideline 383. accidental 384. dance 385. disguise 386. shape 387. training 388. wave 389. dressing 390. cabbage 391. architect 392. leek 393. kielbasa 394. bather 395. allocation 396. helpful 397. participant 398. elated 399. cheerful 400. campus 401. verification 402. riser 403. glutamate 404. attach 405. floozie 406. rush 407. idiotic 408. trial 409. spicy 410. juicy 411. wastebasket 412. null 413. bar 414. nifty 415. inventory 416. portion 417. bark 418. muscatel 419. gastronomy 420. acquisition 421. ectodermal 422. stress 423. gigantic 424. cria 425. camper 426. validate 427. employer 428. championship 429. prosecution 430. bankruptcy 431. influence 432. orient 433. seafood 434. sport 435. ski 436. replication 437. glutamate 438. disguise 439. breakable 440. conduct 441. curved 442. wary 443. guard 444. absorbing 445. definition 446. compulsion 447. adviser 448. verdant 449. beautiful 450. durian 451. struggle 452. strong 453. quince 454. parsley 455. draconian 456. strawman 457. rescue 458. successful 459. curly 460. moose 461. otter 462. reveal 463. success 464. advance 465. celebration 466. airfare 467. dial 468. steak 469. denominator 470. cake 471. amazement 472. dazzling 473. glutamate 474. amuse 475. menorah 476. blow 477. sunbonnet 478. constraint 479. candelabra 480. bin 481. lumber 482. samovar 483. batter 484. grab-bag 485. masonry 486. temperature 487. device 488. shrine 489. guess 490. hill 491. booking 492. constraint 493. cummerbund 494. formicarium 495. redirect 496. elimination 497. accompanist 498. famous 499. fuzzy 500. stepmother 501. oatmeal 502. pigsty 503. flour 504. tearful 505. suggestion 506. announcement 507. freezing 508. workplace 509. practice 510. scale 511. apprehension 512. ash 513. bird 514. mutation 515. restoration 516. behold 517. lewd 518. interchange 519. blackberry 520. authorisation 521. pudding 522. tumbler 523. gain 524. pear 525. inability 526. accident 527. menorah 528. constraint 529. indication 530. chino 531. motorcycle 532. heater 533. scrap 534. garment 535. breakdown 536. ginseng 537. hydrant 538. tabernacle 539. herbs 540. substance 541. sunflower 542. tortellini 543. millimeter 544. labour 545. nostalgic 546. sleuth 547. menorah 548. virtue 549. mouser 550. profit 551. carpeting 552. snobbish 553. modern 554. ruthless 555. hackwork 556. cheese 557. trapezoid 558. illness 559. kit 560. pin 561. colony 562. prickly 563. rug 564. disprove 565. abusive 566. enjoyment 567. disclosure 568. limitation 569. kebab 570. anesthesiologist 571. sail 572. weed 573. peripheral 574. disguise 575. orchard 576. bright 577. numerous 578. constraint 579. understood 580. chives 581. genre 582. room 583. export 584. bayou 585. assistance 586. sovereignty 587. homosexual 588. salesman 589. kiss 590. noise 591. supernatural 592. inhabitant 593. leave 594. pop 595. crew 596. unarmed 597. saxophone 598. candy 599. initial 600. boyhood 601. leeway 602. low 603. feather 604. callous 605. warming 606. overcoat 607. frenzy 608. elimination 609. gelding 610. fanlight 611. burial 612. marmalade 613. elimination 614. vintage 615. tunnel 616. harmonise 617. reveal 618. rubric 619. sword 620. cathedral 621. behaviour 622. lot 623. north 624. advocacy 625. tutu 626. special 627. enlist 628. contest 629. psychiatrist 630. tomb 631. examiner 632. idiotic 633. youngster 634. back 635. washbasin 636. co-producer 637. incident 638. pistol 639. grocery 640. rite 641. emphasis 642. constraint 643. burning 644. caboose 645. subtitle 646. monitoring 647. fries 648. caravan 649. circuit 650. livestock 651. gelatin 652. hippopotamus 653. last 654. crazy 655. obstacle 656. impudence 657. bond 658. minnow 659. replica 660. ex-husband 661. alloy 662. fat 663. farrow 664. reform 665. tight 666. deliberation 667. sleepiness 668. composite 669. texture 670. competition 671. fob 672. gearshift 673. embarrassment 674. burden 675. stale 676. creep 677. electronics 678. smoke 679. designation 680. late 681. abdomen 682. analyst 683. flavor 684. essence 685. nitrogen 686. invitation 687. incarnation 688. councilor 689. wrist 690. disguise 691. wear 692. pinot 693. cobbler 694. evaluation 695. manacle 696. carrier 697. info 698. confirmation 699. codling 700. statuesque 701. smelting 702. sociology 703. accountability 704. hurt 705. gap 706. oyster 707. telescreen 708. genius 709. pledge 710. yolk 711. rotation 712. span 713. marked 714. reward 715. inevitable 716. coin 717. rose 718. worried 719. occupation 720. republican 721. final 722. drab 723. lute 724. shape 725. refreshments 726. remember 727. taboo 728. snap 729. clutch 730. mass 731. tinderbox 732. maggot 733. second 734. film 735. disaster 736. incentive 737. sneaky 738. possibility 739. glutamate 740. wing 741. slipper 742. withdrawal 743. note 744. seeker 745. driving 746. doe 747. humorous 748. calculator 749. popsicle 750. strawberry 751. prescription 752. bank 753. kite 754. geyser 755. theme 756. shape 757. basement 758. oat 759. harald 760. dollar 761. necktie 762. role 763. zealous 764. heaven 765. strobe 766. hammer 767. platform 768. disguise 769. pride 770. monocle 771. claim 772. formamide 773. polyp 774. reveal 775. restoration 776. cover 777. ridge 778. minute 779. whey 780. reception 781. stew 782. bottling 783. ikebana 784. shelter 785. readiness 786. spooky 787. frantic 788. souvenir 789. menorah 790. depression 791. pioneer\n",
      "Question: What are the 10 most common words in the above list? Answer: The top 10 words that appear most often in the list are:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<answer>\n"
     ]
    }
   ],
   "source": [
    "ruler_train_data = pd.DataFrame({\n",
    "    'prompt': [x['input'].replace(prev_prompt, new_prompt) for x in train_base],\n",
    "    #'predicted_answer': [x['completion'] for x in train_base],\n",
    "    'true_answer': [x['reference'] for x in train_base],\n",
    "    #'prompt': [x['input'] + x['completion'] + '<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n' + get_confidence_prompt('default')[:-13] + \"<|eot_id|>\" + \"\\n<|start_header_id|>assistant<|end_header_id|>\" + \"<confidence>\" for x in train_base],\n",
    "    #'tf': train_tf\n",
    "})\n",
    "\n",
    "ruler_valid_data = pd.DataFrame({\n",
    "    'prompt': [x['input'].replace(prev_prompt, new_prompt)  for x in valid_base],\n",
    "    #'predicted_answer': [x['completion'] for x in valid_base],\n",
    "    'true_answer': [x['reference'] for x in valid_base],\n",
    "    #'prompt': [x['input'] + x['completion'] + '<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n' + get_confidence_prompt('default')[:-13] + \"<|eot_id|>\" + \"\\n<|start_header_id|>assistant<|end_header_id|>\" + \"<confidence>\" for x in valid_base],\n",
    "    #'tf': valid_tf\n",
    "})\n",
    "\n",
    "print(ruler_train_data['prompt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c65a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_prompt = \"\"\"You are a reasoning assistant.\n",
    "Given a question, think step by step to arrive at the correct answer.\n",
    "First, provide your reasoning enclosed in <think> and </think> tags.\n",
    "Then, provide the final answer enclosed in <answer> and </answer> tags.\n",
    "The <answer> tag must contain only the final answer, with no additional explanation.\"\"\"\n",
    "new_prompt = \"\"\"You are a reasoning assistant.\n",
    "Given a question, think step by step to arrive at the correct answer.\n",
    "First, provide your reasoning enclosed in <think> and </think> tags.\n",
    "Then, provide the final answer enclosed in <answer> and </answer> tags.\n",
    "The <answer> tag must contain only the final answer, with no additional explanation.\n",
    "Also provide your confidence enclosed in <confidence> and </confidence> tags.\n",
    "The <confidence> tag must contain only a single number from 0 to 100.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "918bbba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_base = read_jsonl('../logs/trash/llama/gsm_seed_samples/outputs_base_argmax.jsonl')\n",
    "gsm_base_parsed = read_jsonl('../logs/trash/llama/gsm_seed_samples/outputs_base_argmax_parsed.jsonl')\n",
    "   \n",
    "gsm_tf = []\n",
    "for i in range(len(gsm_base)):\n",
    "    try:\n",
    "        if re.sub(r'[^0-9]', '', gsm_base_parsed[i]['parsed'].split(\"**Model's Final Answer is:** \")[-1]).lower() == re.sub(r'[^0-9]', '', extract_hash_answer(gsm_base[i]['reference'])).lower():\n",
    "            gsm_tf.append(1)\n",
    "        else:\n",
    "            gsm_tf.append(0)\n",
    "    except:\n",
    "        gsm_tf.append(0)\n",
    "\n",
    "full_data = pd.DataFrame({\n",
    "    'prompt': [x['input'].replace(prev_prompt, new_prompt) for x in gsm_base],\n",
    "    #'predicted_answer': [x['completion'] for x in gsm_base],\n",
    "    'true_answer': [extract_hash_answer(x['reference']) for x in gsm_base],\n",
    "    #'prompt': [x['input'] + x['completion'] + '<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n' + get_confidence_prompt('default')[:-13] + \"<|eot_id|>\" + \"\\n<|start_header_id|>assistant<|end_header_id|>\" + \"<confidence>\" for x in gsm_base],\n",
    "    #'tf': gsm_tf\n",
    "})\n",
    "\n",
    "full_data = full_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "gsm_train_data = full_data.iloc[:int(len(full_data)*0.8)]\n",
    "gsm_valid_data = full_data.iloc[int(len(full_data)*0.8):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14382ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 14 Jan 2026\n",
      "\n",
      "You are an expert assistant that provides clear and helpful answers.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "You are a reasoning assistant.\n",
      "Given a question, think step by step to arrive at the correct answer.\n",
      "First, provide your reasoning enclosed in <think> and </think> tags.\n",
      "Then, provide the final answer enclosed in <answer> and </answer> tags.\n",
      "The <answer> tag must contain only the final answer, with no additional explanation.\n",
      "Also provide your confidence enclosed in <confidence> and </confidence> tags.\n",
      "The <confidence> tag must contain only a single number from 0 to 100.\n",
      "\n",
      "In Professor Plum's biology class there are 40 students. Of those students, 80 percent have puppies. Of those who have puppies, 25% also have parrots. How many students have both puppies and parrots?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<think>\n"
     ]
    }
   ],
   "source": [
    "print(gsm_train_data['prompt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0b35d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler_train_data.to_csv(\"../data/train_data/Llama-3.2-3B-Instruct/rl_base/ruler_4k_train.csv\", index=False)\n",
    "ruler_valid_data.to_csv(\"../data/train_data/Llama-3.2-3B-Instruct/rl_base/ruler_4k_valid.csv\", index=False)\n",
    "gsm_train_data.to_csv(\"../data/train_data/Llama-3.2-3B-Instruct/rl_base/gsm_train.csv\", index=False)\n",
    "gsm_valid_data.to_csv(\"../data/train_data/Llama-3.2-3B-Instruct/rl_base/gsm_valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c9dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
